{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f08ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sshre35\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sshre35\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\sshre35\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\sshre35\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sshre35\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sshre35\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%run lib.ipynb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e8952fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "DATA_DIR = \"../data/raw reviews/\"\n",
    "domains = [\"ride\", \"investing\", \"health\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba9c09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess - TOKENIZE, REMOVE STOPWORDS, REMOVE (PUNCUTATIONS, DOUBLE QUOTES)  \n",
    "\n",
    "# @param reviews_word_arr (array): each row is (raw review, list of (raw sentence, list of words))\n",
    "# @returns cleaned_sent_reviews (array): each row is (raw review, list of (raw sentence, list of words))\n",
    "# @implementation: removes tokens that have frequencies lower than min_freq \n",
    "def remove_lower_tf_tokens(reviews_word_arr, min_freq = 3):\n",
    "    all_words = []\n",
    "    formatted_review_sent_words = [] \n",
    "    for review, sent_words in reviews_word_arr:\n",
    "        for raw_sent, words in sent_words:\n",
    "            valid_words = [word for word in words if word not in custom_stop_words]\n",
    "            all_words.extend(valid_words)\n",
    "            formatted_review_sent_words.append((review, raw_sent, valid_words))                    \n",
    "    word_counts = Counter(all_words)\n",
    "    cleaned_sent_reviews = []\n",
    "    for raw_review, raw_sent, words in formatted_review_sent_words:\n",
    "        cleaned_words = [word for word in words if word not in custom_stop_words and word_counts[word] > min_freq]\n",
    "        cleaned_sent_reviews.append((raw_review, raw_sent, cleaned_words))\n",
    "    return cleaned_sent_reviews\n",
    "\n",
    "# @param text (string): review text (a document)\n",
    "# @returns sent_tokens (array of array): each row represents a sentence in the review text, \n",
    "# and each row contains an array of words\n",
    "# @implementation: break each review into sentences, and each sentence into words \n",
    "# (each word having more than 2 characters)\n",
    "def extract_sent_words(text, remove_numbers=True):\n",
    "    cleaned_text = clean_text(text)\n",
    "    sent_tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        tokens = nltk_tokenize(sent.lower())\n",
    "        tokens = nltk_remove_stopwords(tokens, custom_stop_words)\n",
    "        # get each word of size more than 2\n",
    "        filtered_words = clean_sent_words(tokens, 2) \n",
    "        if filtered_words:\n",
    "            sent_tokens.append((sent, filtered_words))\n",
    "    return sent_tokens\n",
    "\n",
    "# @returns a tuple (string, array of array): first item is review document, \n",
    "# second item is list of list of words representing tokenized sentences in the review\n",
    "# @implementation: breaks down review_text (string) into tokenized sentences\n",
    "def break_sent_into_words(review_text):\n",
    "    extracted_sent_words = extract_sent_words(review_text)\n",
    "    return (review_text, extracted_sent_words)\n",
    "\n",
    "# @returns an array of processed reviews\n",
    "def break_sentences_into_words(reviews_arr):\n",
    "    return [break_sent_into_words(review_text) for review_text in reviews_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e00158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_reviews_arr(reviews_arr, lemma = True):\n",
    "    tokenized_sent_reviews = break_sentences_into_words(reviews_arr)\n",
    "    tokenized_reviews = remove_lower_tf_tokens(tokenized_sent_reviews)\n",
    "    if lemma:\n",
    "        review_arr_lemmatized = [(raw_review, review_sent, nltk_lemmatize_post_tag_rev_words(sent_words)) for (raw_review, review_sent, sent_words) in tokenized_reviews]\n",
    "        return review_arr_lemmatized\n",
    "    return tokenized_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af36d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_reviews(input_csv):\n",
    "    reviews_df = pd.read_csv(input_csv, usecols=[\"Domain\", \"Name\", \"Title\", \"Date\", \"UserName\", \"Review\", \"Rating\"])\n",
    "    reviews_df[\"Review\"] = reviews_df[\"Review\"].apply(lambda x: x.encode(\"ascii\", errors=\"ignore\").decode())\n",
    "    return reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90cca3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, lemmatize=False):\n",
    "    reviews_arr = df[\"Review\"].tolist()\n",
    "    processed_sentences = preprocess_reviews_arr(reviews_arr, lemmatize)\n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b27517",
   "metadata": {},
   "source": [
    "### Load raw reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d7b83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_raw_reviews = {}\n",
    "\n",
    "for domain in domains:\n",
    "    input_csv_file = DATA_DIR + domain + \".csv\"\n",
    "    _df = load_raw_reviews(input_csv_file)\n",
    "    domain_raw_reviews[domain] = _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca0a8542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RideHailing</td>\n",
       "      <td>99-private-drivers-and-taxi</td>\n",
       "      <td>Awful</td>\n",
       "      <td>12/14/20 0:00</td>\n",
       "      <td>veronica in new york</td>\n",
       "      <td>someone made an account on this app using my e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RideHailing</td>\n",
       "      <td>99-private-drivers-and-taxi</td>\n",
       "      <td>Lost money on many transactions</td>\n",
       "      <td>7/8/21 15:05</td>\n",
       "      <td>nick22485</td>\n",
       "      <td>if you can use uber eats. this app has been la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RideHailing</td>\n",
       "      <td>99-private-drivers-and-taxi</td>\n",
       "      <td>Let me turn off your annoying notifications</td>\n",
       "      <td>5/15/21 21:53</td>\n",
       "      <td>voska</td>\n",
       "      <td>any other app, i would just disable notificati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RideHailing</td>\n",
       "      <td>99-private-drivers-and-taxi</td>\n",
       "      <td>Can't retrieve my email</td>\n",
       "      <td>11/6/21 18:27</td>\n",
       "      <td>PNC.406</td>\n",
       "      <td>your security is pathetic. you allow users to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RideHailing</td>\n",
       "      <td>99-private-drivers-and-taxi</td>\n",
       "      <td>I want to set the addresses. Do not change it</td>\n",
       "      <td>8/26/21 11:35</td>\n",
       "      <td>rcv</td>\n",
       "      <td>when i want to call a ride for someone else th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Domain                         Name  \\\n",
       "0  RideHailing  99-private-drivers-and-taxi   \n",
       "1  RideHailing  99-private-drivers-and-taxi   \n",
       "2  RideHailing  99-private-drivers-and-taxi   \n",
       "3  RideHailing  99-private-drivers-and-taxi   \n",
       "4  RideHailing  99-private-drivers-and-taxi   \n",
       "\n",
       "                                           Title           Date  \\\n",
       "0                                          Awful  12/14/20 0:00   \n",
       "1                Lost money on many transactions   7/8/21 15:05   \n",
       "2    Let me turn off your annoying notifications  5/15/21 21:53   \n",
       "3                        Can't retrieve my email  11/6/21 18:27   \n",
       "4  I want to set the addresses. Do not change it  8/26/21 11:35   \n",
       "\n",
       "               UserName                                             Review  \\\n",
       "0  veronica in new york  someone made an account on this app using my e...   \n",
       "1             nick22485  if you can use uber eats. this app has been la...   \n",
       "2                 voska  any other app, i would just disable notificati...   \n",
       "3               PNC.406  your security is pathetic. you allow users to ...   \n",
       "4                   rcv  when i want to call a ride for someone else th...   \n",
       "\n",
       "   Rating  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_raw_reviews[\"ride\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d83ec63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Investing</td>\n",
       "      <td>acorns-invest-spare-change</td>\n",
       "      <td>Great for Investing - Spend is garbage</td>\n",
       "      <td>7/7/2022 22:25</td>\n",
       "      <td>Alex Beckett</td>\n",
       "      <td>i like investing on here. yeah, savings are ma...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investing</td>\n",
       "      <td>acorns-invest-spare-change</td>\n",
       "      <td>Unnecessarily Complicated</td>\n",
       "      <td>7/24/2022 7:13</td>\n",
       "      <td>TeaCup Velvet</td>\n",
       "      <td>i am not going to pull any punches here. if yo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Investing</td>\n",
       "      <td>acorns-invest-spare-change</td>\n",
       "      <td>Poor customer service</td>\n",
       "      <td>12/28/2021 15:23</td>\n",
       "      <td>Jfishllc</td>\n",
       "      <td>i'm rating this app 1 star because of poor cus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Investing</td>\n",
       "      <td>acorns-invest-spare-change</td>\n",
       "      <td>Transaction Dispute</td>\n",
       "      <td>8/28/2022 20:38</td>\n",
       "      <td>victimofacorns</td>\n",
       "      <td>a fraudulent company accessed my checking acco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Investing</td>\n",
       "      <td>acorns-invest-spare-change</td>\n",
       "      <td>Great concept, but needs serious improvement</td>\n",
       "      <td>7/9/2021 17:48</td>\n",
       "      <td>144278990</td>\n",
       "      <td>make unlinking accounts actually unlink accoun...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Domain                        Name  \\\n",
       "0  Investing  acorns-invest-spare-change   \n",
       "1  Investing  acorns-invest-spare-change   \n",
       "2  Investing  acorns-invest-spare-change   \n",
       "3  Investing  acorns-invest-spare-change   \n",
       "4  Investing  acorns-invest-spare-change   \n",
       "\n",
       "                                          Title              Date  \\\n",
       "0        Great for Investing - Spend is garbage    7/7/2022 22:25   \n",
       "1                     Unnecessarily Complicated    7/24/2022 7:13   \n",
       "2                         Poor customer service  12/28/2021 15:23   \n",
       "3                           Transaction Dispute   8/28/2022 20:38   \n",
       "4  Great concept, but needs serious improvement    7/9/2021 17:48   \n",
       "\n",
       "         UserName                                             Review  Rating  \n",
       "0    Alex Beckett  i like investing on here. yeah, savings are ma...       3  \n",
       "1   TeaCup Velvet  i am not going to pull any punches here. if yo...       2  \n",
       "2        Jfishllc  i'm rating this app 1 star because of poor cus...       1  \n",
       "3  victimofacorns  a fraudulent company accessed my checking acco...       1  \n",
       "4       144278990  make unlinking accounts actually unlink accoun...       2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_raw_reviews[\"investing\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d810c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mental Health</td>\n",
       "      <td>aura-meditation-sleep</td>\n",
       "      <td>Finally able to fall asleep!</td>\n",
       "      <td>3/25/2022 18:16</td>\n",
       "      <td>2005Phoenix</td>\n",
       "      <td>i've tried many sleep apps the last few years,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mental Health</td>\n",
       "      <td>aura-meditation-sleep</td>\n",
       "      <td>Best Sleep Since 10+ Years</td>\n",
       "      <td>10/22/2021 12:59</td>\n",
       "      <td>Marissa Lee B</td>\n",
       "      <td>i haven't been sleeping well honestly in these...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mental Health</td>\n",
       "      <td>aura-meditation-sleep</td>\n",
       "      <td>Perfectly curated blend of options to sleep by</td>\n",
       "      <td>1/7/2022 9:44</td>\n",
       "      <td>Mybellegirls</td>\n",
       "      <td>and reliable for its intended use xoxo! five g...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mental Health</td>\n",
       "      <td>aura-meditation-sleep</td>\n",
       "      <td>Warning: canceling is extremely difficult</td>\n",
       "      <td>2/6/2022 2:05</td>\n",
       "      <td>ndmel3</td>\n",
       "      <td>though the couple of items i listened to on au...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mental Health</td>\n",
       "      <td>aura-meditation-sleep</td>\n",
       "      <td>If I can, You certainly can...</td>\n",
       "      <td>2/21/2021 20:41</td>\n",
       "      <td>AppFixation</td>\n",
       "      <td>i've never been a person that could stop doing...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Domain                   Name  \\\n",
       "0  Mental Health  aura-meditation-sleep   \n",
       "1  Mental Health  aura-meditation-sleep   \n",
       "2  Mental Health  aura-meditation-sleep   \n",
       "3  Mental Health  aura-meditation-sleep   \n",
       "4  Mental Health  aura-meditation-sleep   \n",
       "\n",
       "                                            Title              Date  \\\n",
       "0                    Finally able to fall asleep!   3/25/2022 18:16   \n",
       "1                      Best Sleep Since 10+ Years  10/22/2021 12:59   \n",
       "2  Perfectly curated blend of options to sleep by     1/7/2022 9:44   \n",
       "3       Warning: canceling is extremely difficult     2/6/2022 2:05   \n",
       "4                  If I can, You certainly can...   2/21/2021 20:41   \n",
       "\n",
       "        UserName                                             Review  Rating  \n",
       "0    2005Phoenix  i've tried many sleep apps the last few years,...       5  \n",
       "1  Marissa Lee B  i haven't been sleeping well honestly in these...       5  \n",
       "2   Mybellegirls  and reliable for its intended use xoxo! five g...       5  \n",
       "3         ndmel3  though the couple of items i listened to on au...       2  \n",
       "4    AppFixation  i've never been a person that could stop doing...       5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_raw_reviews[\"health\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc05d830",
   "metadata": {},
   "source": [
    "### Tokenize review sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa29991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_tokenized_reviews = {}\n",
    "\n",
    "for domain in domains[:1]:\n",
    "    _df = domain_raw_reviews[domain]\n",
    "    tokenized_reviews = preprocess(_df)\n",
    "    domain_tokenized_reviews[domain] = tokenized_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e14621ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain in domains[:1]:\n",
    "    _tokenized = domain_tokenized_reviews[domain]\n",
    "    _df = pd.DataFrame(_tokenized, columns=[\"review\", \"sent\" ,\"tokenized\"])\n",
    "    _df[\"word count\"] = _df[\"tokenized\"].apply(lambda x: len(x))\n",
    "    tokenized_file = DATA_DIR + domain + \"_tokenized.csv\"\n",
    "    _df.to_csv(tokenized_file, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "680f3e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sent</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>word count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>someone made an account on this app using my e...</td>\n",
       "      <td>someone made an account on this app using my e...</td>\n",
       "      <td>['someone', 'made', 'account', 'app', 'using',...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>someone made an account on this app using my e...</td>\n",
       "      <td>i get all of their receipts, trip info, and cu...</td>\n",
       "      <td>['get', 'receipts', 'trip', 'info', 'customer'...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>someone made an account on this app using my e...</td>\n",
       "      <td>they don't even have remotely the same name as...</td>\n",
       "      <td>['even', 'remotely', 'name', 'emailed', 'sever...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>someone made an account on this app using my e...</td>\n",
       "      <td>they had me describe myself to prove it's inco...</td>\n",
       "      <td>['describe', 'prove', 'incorrect', 'still', 'e...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>someone made an account on this app using my e...</td>\n",
       "      <td>they should at least have some sort of email v...</td>\n",
       "      <td>['least', 'sort', 'email', 'verification', 'pr...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  someone made an account on this app using my e...   \n",
       "1  someone made an account on this app using my e...   \n",
       "2  someone made an account on this app using my e...   \n",
       "3  someone made an account on this app using my e...   \n",
       "4  someone made an account on this app using my e...   \n",
       "\n",
       "                                                sent  \\\n",
       "0  someone made an account on this app using my e...   \n",
       "1  i get all of their receipts, trip info, and cu...   \n",
       "2  they don't even have remotely the same name as...   \n",
       "3  they had me describe myself to prove it's inco...   \n",
       "4  they should at least have some sort of email v...   \n",
       "\n",
       "                                           tokenized  word count  \n",
       "0  ['someone', 'made', 'account', 'app', 'using',...           7  \n",
       "1  ['get', 'receipts', 'trip', 'info', 'customer'...           7  \n",
       "2  ['even', 'remotely', 'name', 'emailed', 'sever...           9  \n",
       "3  ['describe', 'prove', 'incorrect', 'still', 'e...           5  \n",
       "4  ['least', 'sort', 'email', 'verification', 'pr...           9  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(DATA_DIR + \"ride_tokenized.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe6a08a",
   "metadata": {},
   "source": [
    "### Lemmatize sentence tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c88be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_lemmatized_reviews = {}\n",
    "\n",
    "for domain in domains:\n",
    "    tokenized_reviews = domain_tokenized_reviews[domain]\n",
    "    lemmatized_reviews = [(raw_review, review_sent, sent_words, nltk_lemmatize_post_tag_rev_words(sent_words)) for (raw_review, review_sent, sent_words) in tokenized_reviews]\n",
    "    domain_lemmatized_reviews[domain] = lemmatized_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12aea330",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain in domains:\n",
    "    lemmatized_reviews = domain_lemmatized_reviews[domain]\n",
    "    _df = pd.DataFrame(lemmatized_reviews, columns=[\"review\", \"sent\", \"tokenized\",\"lemmatized\"])\n",
    "    _df[\"tokenized\"] = _df[\"tokenized\"].apply(lambda x: \",\".join(x))\n",
    "    _df[\"word count\"] = _df[\"lemmatized\"].apply(lambda x: len(x.split(\",\")) if x else 0)\n",
    "    lemmatized_file = DATA_DIR + domain + \"_lemmatized.csv\"\n",
    "    _df.to_csv(lemmatized_file, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "941927ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sent</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>word count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>someone made an account on this app using my e...</td>\n",
       "      <td>someone made an account on this app using my e...</td>\n",
       "      <td>someone,made,account,app,using,email,address</td>\n",
       "      <td>someone,make,account,app,use,email,address</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>someone made an account on this app using my e...</td>\n",
       "      <td>i get all of their receipts, trip info, and cu...</td>\n",
       "      <td>get,receipts,trip,info,customer,service,responses</td>\n",
       "      <td>get,receipt,trip,info,customer,service,response</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>someone made an account on this app using my e...</td>\n",
       "      <td>they don't even have remotely the same name as...</td>\n",
       "      <td>even,remotely,name,emailed,several,times,ask,s...</td>\n",
       "      <td>even,remotely,name,email,several,time,ask,stop...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>someone made an account on this app using my e...</td>\n",
       "      <td>they had me describe myself to prove it's inco...</td>\n",
       "      <td>describe,prove,incorrect,still,emailing</td>\n",
       "      <td>describe,prove,incorrect,still,email</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>someone made an account on this app using my e...</td>\n",
       "      <td>they should at least have some sort of email v...</td>\n",
       "      <td>least,sort,email,verification,prove,emailing,v...</td>\n",
       "      <td>least,sort,email,verification,prove,email,vali...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  someone made an account on this app using my e...   \n",
       "1  someone made an account on this app using my e...   \n",
       "2  someone made an account on this app using my e...   \n",
       "3  someone made an account on this app using my e...   \n",
       "4  someone made an account on this app using my e...   \n",
       "\n",
       "                                                sent  \\\n",
       "0  someone made an account on this app using my e...   \n",
       "1  i get all of their receipts, trip info, and cu...   \n",
       "2  they don't even have remotely the same name as...   \n",
       "3  they had me describe myself to prove it's inco...   \n",
       "4  they should at least have some sort of email v...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0       someone,made,account,app,using,email,address   \n",
       "1  get,receipts,trip,info,customer,service,responses   \n",
       "2  even,remotely,name,emailed,several,times,ask,s...   \n",
       "3            describe,prove,incorrect,still,emailing   \n",
       "4  least,sort,email,verification,prove,emailing,v...   \n",
       "\n",
       "                                          lemmatized  word count  \n",
       "0         someone,make,account,app,use,email,address           7  \n",
       "1    get,receipt,trip,info,customer,service,response           7  \n",
       "2  even,remotely,name,email,several,time,ask,stop...           9  \n",
       "3               describe,prove,incorrect,still,email           5  \n",
       "4  least,sort,email,verification,prove,email,vali...           9  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(DATA_DIR + \"/lemmatized/ride_lemmatized.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26929e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sent</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>word count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i like investing on here. yeah, savings are ma...</td>\n",
       "      <td>i like investing on here.</td>\n",
       "      <td>like,investing</td>\n",
       "      <td>like,invest</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i like investing on here. yeah, savings are ma...</td>\n",
       "      <td>yeah, savings are mainly through round-ups, bu...</td>\n",
       "      <td>yeah,savings,mainly,roundups,saved,lot</td>\n",
       "      <td>yeah,saving,mainly,roundup,save,lot</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i like investing on here. yeah, savings are ma...</td>\n",
       "      <td>the spend account, however, neither makes sens...</td>\n",
       "      <td>spend,account,however,neither,makes,sense,conn...</td>\n",
       "      <td>spend,account,however,neither,make,sense,conne...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i like investing on here. yeah, savings are ma...</td>\n",
       "      <td>you would think you could just move money betw...</td>\n",
       "      <td>would,think,could,move,money,accounts,really,o...</td>\n",
       "      <td>would,think,could,move,money,account,really,on...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i like investing on here. yeah, savings are ma...</td>\n",
       "      <td>so i have no idea what the point is.</td>\n",
       "      <td>idea,point</td>\n",
       "      <td>idea,point</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  i like investing on here. yeah, savings are ma...   \n",
       "1  i like investing on here. yeah, savings are ma...   \n",
       "2  i like investing on here. yeah, savings are ma...   \n",
       "3  i like investing on here. yeah, savings are ma...   \n",
       "4  i like investing on here. yeah, savings are ma...   \n",
       "\n",
       "                                                sent  \\\n",
       "0                          i like investing on here.   \n",
       "1  yeah, savings are mainly through round-ups, bu...   \n",
       "2  the spend account, however, neither makes sens...   \n",
       "3  you would think you could just move money betw...   \n",
       "4               so i have no idea what the point is.   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0                                     like,investing   \n",
       "1             yeah,savings,mainly,roundups,saved,lot   \n",
       "2  spend,account,however,neither,makes,sense,conn...   \n",
       "3  would,think,could,move,money,accounts,really,o...   \n",
       "4                                         idea,point   \n",
       "\n",
       "                                          lemmatized  word count  \n",
       "0                                        like,invest           2  \n",
       "1                yeah,saving,mainly,roundup,save,lot           6  \n",
       "2  spend,account,however,neither,make,sense,conne...          10  \n",
       "3  would,think,could,move,money,account,really,on...          11  \n",
       "4                                         idea,point           2  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(DATA_DIR + \"/lemmatized/investing_lemmatized.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da34cb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sent</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>word count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i've tried many sleep apps the last few years,...</td>\n",
       "      <td>i've tried many sleep apps the last few years,...</td>\n",
       "      <td>tried,many,sleep,apps,last,years,helped,extent...</td>\n",
       "      <td>try,many,sleep,apps,last,year,help,extent,none...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i've tried many sleep apps the last few years,...</td>\n",
       "      <td>there are dozens - maybe hundreds - to choose ...</td>\n",
       "      <td>dozens,maybe,hundreds,choose,tell,within,minut...</td>\n",
       "      <td>dozen,maybe,hundred,choose,tell,within,minute,...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i've tried many sleep apps the last few years,...</td>\n",
       "      <td>in the trial period, i was already figuring ou...</td>\n",
       "      <td>trial,period,already,figuring,individuals,want...</td>\n",
       "      <td>trial,period,already,figure,individual,want,fo...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've tried many sleep apps the last few years,...</td>\n",
       "      <td>in the past, lying with my eyes closed trying ...</td>\n",
       "      <td>past,lying,eyes,closed,trying,sleep,would,wind...</td>\n",
       "      <td>past,lie,eye,close,try,sleep,would,wind,make,f...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've tried many sleep apps the last few years,...</td>\n",
       "      <td>listening to the hypnosis audio that i like ta...</td>\n",
       "      <td>listening,hypnosis,audio,like,takes,place,open...</td>\n",
       "      <td>listen,hypnosis,audio,like,take,place,openness...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  i've tried many sleep apps the last few years,...   \n",
       "1  i've tried many sleep apps the last few years,...   \n",
       "2  i've tried many sleep apps the last few years,...   \n",
       "3  i've tried many sleep apps the last few years,...   \n",
       "4  i've tried many sleep apps the last few years,...   \n",
       "\n",
       "                                                sent  \\\n",
       "0  i've tried many sleep apps the last few years,...   \n",
       "1  there are dozens - maybe hundreds - to choose ...   \n",
       "2  in the trial period, i was already figuring ou...   \n",
       "3  in the past, lying with my eyes closed trying ...   \n",
       "4  listening to the hypnosis audio that i like ta...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  tried,many,sleep,apps,last,years,helped,extent...   \n",
       "1  dozens,maybe,hundreds,choose,tell,within,minut...   \n",
       "2  trial,period,already,figuring,individuals,want...   \n",
       "3  past,lying,eyes,closed,trying,sleep,would,wind...   \n",
       "4  listening,hypnosis,audio,like,takes,place,open...   \n",
       "\n",
       "                                          lemmatized  word count  \n",
       "0  try,many,sleep,apps,last,year,help,extent,none...          14  \n",
       "1  dozen,maybe,hundred,choose,tell,within,minute,...          10  \n",
       "2  trial,period,already,figure,individual,want,fo...          12  \n",
       "3  past,lie,eye,close,try,sleep,would,wind,make,f...          11  \n",
       "4  listen,hypnosis,audio,like,take,place,openness...          10  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(DATA_DIR + \"/lemmatized/health_lemmatized.csv\").head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
